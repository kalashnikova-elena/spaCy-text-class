{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nnlp = spacy.blank('en')\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\n\nnlp.add_pipe(textcat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"textcat.add_label('yes')\ntextcat.add_label('no')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text = data.text.values\ntrain_labels = [{'cats': {'yes' : l== 1, 'no': l==0}} for l in data.target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = list(zip(train_text, train_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from spacy.util import minibatch\nimport random\nrandom.seed(1) #one random process\nspacy.util.fix_random_seed(1) #\noptimizer = nlp.begin_training()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = {}\nfor epoch in range(10):\n    random.shuffle(train_data)\n    batches = minibatch(train_data, size=8)\n    for batch in batches:\n        texts, labels = zip(*batch) #unzip\n        nlp.update(texts, labels, sgd=optimizer, losses = losses)\n    print(losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from exersize\ntext = [\"This tea cup was full of holes. Do not recommend.\",\"Fire! Caution!!! Seek shelter\", \"Buy me a barbie doll\"]\ndoc = [nlp.tokenizer(t) for t in text]\ntextcat = nlp.get_pipe('textcat')\nscores, _ = textcat.predict(doc) #????\nprint(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_l = scores.argmax(axis = 1)\nprint([textcat.labels[l] for l in predict_l])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test_d = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_d['text'].values\ntest[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tt = test\ndoc = [nlp.tokenizer(t) for t in tt]\ntextcat = nlp.get_pipe('textcat')\nscores, _ = textcat.predict(doc) \nprint(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_l = scores.argmin(axis = 1)\nprint([textcat.labels[l] for l in predict_l])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tab_submit = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv', header = 0, names = ['id','target'])\ntab_submit.to_csv('submission_Ready.csv', index = False)\ntab_submit['target'] = predict_l\ntab_submit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tab_submit.to_csv('submission_Ready.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}